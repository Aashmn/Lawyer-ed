{"cells":[{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"No files found in data.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load and index documents\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleDirectoryReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[0;32m     11\u001b[0m parser \u001b[38;5;241m=\u001b[39m SimpleNodeParser\u001b[38;5;241m.\u001b[39mfrom_defaults()\n\u001b[0;32m     12\u001b[0m nodes \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mget_nodes_from_documents(documents)\n","File \u001b[1;32mc:\\Users\\aashm\\OneDrive\\Desktop\\App Project\\.venv\\lib\\site-packages\\llama_index\\core\\readers\\file\\base.py:263\u001b[0m, in \u001b[0;36mSimpleDirectoryReader.__init__\u001b[1;34m(self, input_dir, input_files, exclude, exclude_hidden, errors, recursive, encoding, filename_as_id, required_exts, file_extractor, num_files_limit, file_metadata, raise_on_error, fs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dir \u001b[38;5;241m=\u001b[39m _Path(input_dir)\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude \u001b[38;5;241m=\u001b[39m exclude\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_extractor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_extractor \u001b[38;5;241m=\u001b[39m file_extractor\n","File \u001b[1;32mc:\\Users\\aashm\\OneDrive\\Desktop\\App Project\\.venv\\lib\\site-packages\\llama_index\\core\\readers\\file\\base.py:345\u001b[0m, in \u001b[0;36mSimpleDirectoryReader._add_files\u001b[1;34m(self, input_dir)\u001b[0m\n\u001b[0;32m    342\u001b[0m new_input_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(all_files)\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_input_files) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo files found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_files_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_files_limit \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    348\u001b[0m     new_input_files \u001b[38;5;241m=\u001b[39m new_input_files[\u001b[38;5;241m0\u001b[39m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_files_limit]\n","\u001b[1;31mValueError\u001b[0m: No files found in data."]}],"source":["from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n","from llama_index.core.node_parser import SimpleNodeParser\n","from llama_index.core.schema import MetadataMode\n","from llama_index.core.retrievers import VectorIndexRetriever\n","from llama_index.core.query_engine import RetrieverQueryEngine\n","from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n","from typing import List\n","\n","# Load and index documents\n","documents = SimpleDirectoryReader('data').load_data()\n","parser = SimpleNodeParser.from_defaults()\n","nodes = parser.get_nodes_from_documents(documents)\n","\n","# Assume each node has a 'topic', 'position', 'file_name', and 'file_path' in its metadata\n","for i, node in enumerate(nodes):\n","    node.metadata['position'] = i\n","    node.metadata['file_name'] = f\"file_{i}.txt\"  # Example file name for each node\n","    node.metadata['file_path'] = f\"/path/to/file_{i}.txt\"  # Example file path\n","    node.excluded_llm_metadata_keys = ['file_path']  # Exclude file_path from LLM metadata\n","\n","index = VectorStoreIndex(nodes)\n","\n","def get_topic_position(query: str) -> int:\n","    # This function should identify the topic and return its position\n","    # For simplicity, we're using a basic retrieval method here\n","    retriever = VectorIndexRetriever(index=index, similarity_top_k=1)\n","    retrieved_nodes = retriever.retrieve(query)\n","    return retrieved_nodes[0].metadata['position']\n","\n","def filter_nodes(nodes: List, position: int) -> List:\n","    return [node for node in nodes if node.metadata['position'] <= position]\n","\n","def group_nodes(nodes: List) -> dict:\n","    grouped = {}\n","    for node in nodes:\n","        topic = node.metadata.get('topic', 'Unknown')\n","        if topic not in grouped:\n","            grouped[topic] = []\n","        grouped[topic].append(node)\n","    return grouped\n","\n","def chatbot():\n","    # Get query from user input\n","    query = input(\"Enter your query: \")\n","\n","    # Get the position of the topic from the query\n","    topic_position = get_topic_position(query)\n","\n","    # Filter the nodes before the topic position and the current one\n","    filtered_nodes = filter_nodes(index.docstore.docs.values(), topic_position)\n","\n","    # Group the nodes separately (apply any specific grouping logic here)\n","    grouped_nodes = group_nodes(filtered_nodes)\n","\n","    # Create a new index with the filtered and grouped nodes\n","    new_index = VectorStoreIndex(list(filtered_nodes))\n","    \n","    # Create a retriever and postprocessor\n","    retriever = VectorIndexRetriever(index=new_index, similarity_top_k=2)\n","    postprocessor = MetadataReplacementPostProcessor(target_metadata_key=\"topic\")\n","    \n","    # Create a query engine with the retriever and postprocessor\n","    query_engine = RetrieverQueryEngine(retriever, node_postprocessors=[postprocessor])\n","\n","    # Query the engine and get the response\n","    response = query_engine.query(query)\n","\n","    # Extract the first source node\n","    source_node = response.source_nodes[0].node  # Get the first source node\n","    node_content = source_node.get_content()  # Get the node content (text)\n","\n","    # Assuming the metadata has 'file_name', 'position', and 'file_path' fields\n","    file_name = source_node.metadata.get('file_name', 'Unknown File')\n","    node_position = source_node.metadata.get('position', 'Unknown Position')\n","\n","    # Retrieve the excluded metadata (file_path in this case)\n","    file_path = source_node.metadata.get('file_path', 'Unknown Path') if 'file_path' in source_node.excluded_llm_metadata_keys else 'No File Path'\n","\n","    # Print only the response and the relevant metadata (file name, node position, and file path)\n","    print(f\"Answer: {response}\")\n","    print(f\"File Name: {file_name}\")\n","    print(f\"Node Number: {node_position}\")\n","    print(f\"File Path: {file_path}\")\n","\n","# Run the chatbot\n","chatbot()\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["TextNode(id_='e023f4b4-4dc9-4afb-ad03-ec5468e54d3e', embedding=None, metadata={'page_label': '7', 'file_name': 'file_18.txt', 'file_path': '/path/to/file_18.txt', 'file_type': 'application/pdf', 'file_size': 105401, 'creation_date': '2024-08-27', 'last_modified_date': '2024-08-27', 'position': 18}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_path'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='400635f0-7808-4d15-9e55-e490dcc1a36a', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '7', 'file_name': 'IME_Podcast_014_Valentine_s_Day-PDF.pdf', 'file_path': 'c:\\\\Users\\\\aashm\\\\OneDrive\\\\Desktop\\\\App Project\\\\data\\\\IME_Podcast_014_Valentine_s_Day-PDF.pdf', 'file_type': 'application/pdf', 'file_size': 105401, 'creation_date': '2024-08-27', 'last_modified_date': '2024-08-27'}, hash='c392b0fdbcd7c827c984e75999519637c7a1854aa3d1f67470b81ba92e50ffa0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='73a1cdf5-e916-4a99-afb5-e5bc08f2f2ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d12a4f32afb19d0d2b8f805b6061f8f5c8979645daf93a1aa5725c8098c70b36')}, text='I T A L Y\\nM A D E\\nE A S Y\\nP O D C A S T\\nfesteggiava\\nnon\\nsi\\nadattava\\nper\\nnulla\\nalla\\ncondotta\\npredicata\\ndalla\\nreligione\\ncristiana!\\nE\\nfu\\na\\nquesto\\npunto\\nche\\nentrò\\nin\\nscena\\nil\\nnostro\\nSan\\nValentino.\\nSapete\\nchi\\nera?\\nSapete\\nperché\\nsi\\ndecise\\nche\\nla\\nfesta\\ndegli\\ninnam orati\\nportasse\\nproprio\\nil\\nsuo\\nnom e?\\nEsistono\\ntante\\nleggende\\nin\\nm erito.\\nSecondo\\nquella\\nbritannica,\\nSan\\nValentino\\nera\\nun\\nuom o\\nbuono\\nche\\naiutò\\nuna\\nragazza\\npovera\\na\\nsposarsi,\\nsalvandola\\ncosì\\ndalla\\nperdizione:\\nè\\nper\\nquesto\\nche\\nnel\\nm ondo\\nanglicano\\nsi\\niniziò\\na\\nconsiderarlo\\nil\\npatrono\\ndegli\\ninnam orati.\\nM a,\\ncom e\\nstavo\\ndicendo,\\nanche\\nnel\\nm ondo\\ncattolico\\nSan\\nValentino\\nvenne\\nscelto\\ncom e\\nsoggetto\\nda\\nvenerare\\nil\\n14\\nfebbraio…\\ncom e\\nm ai?\\nPresto\\nspiegato:\\nSan\\nValentino\\nè\\nun\\npersonaggio\\nesistente\\nanche\\nnella\\ntradizione\\ncristiano-cattolica.\\nFu\\ninfatti\\nil\\nvescovo\\ndi\\nTerni,\\nin\\nUm bria,\\ne\\nvisse\\n-\\nper\\npoi\\nm orire\\ncom e\\nm artire\\n-\\nnel\\nII\\nsecolo\\nd.\\nC.\\nEbbene\\nsì:\\nSan\\nValentino\\nè\\nun\\npersonaggio\\nche\\nda\\nsecoli\\nviene\\nvenerato\\nper\\naver\\nsacriﬁcato\\nla\\nsua\\nvita\\nin\\nnom e\\ndell’am ore.\\nSi\\nracconta,\\ninfatti,\\nche\\nabbia\\ncelebrato\\n-\\ninfrangendo\\nle\\nregole\\ndel\\ntem po\\n-\\nil\\nm atrim onio\\ntra\\nuna\\nragazza\\ncristiana\\ned\\nun\\nsoldato\\nrom ano\\npagano;\\nquesta\\nfu\\nla\\ncolpa\\nper\\ncui\\nvenne\\ncondannato\\na\\nm orte.\\nInsom m a,\\nsem bra\\nche\\nfosse\\nfam oso\\ngià\\nall’epoca\\nin\\ncui\\nvisse!\\nQ uindi\\nuna\\ncosa\\nè\\ncerta:\\novunque\\nguardiam o,\\na\\nqualsiasi\\nleggenda\\no\\ntradizione\\ndecidiam o\\ndi\\ncredere,\\nsem bra\\nche\\ntutto\\nil\\nm ondo\\nsia\\nd’accordo.\\nSan\\nValentino\\nm erita\\na\\ntutti\\ngli\\neffetti\\ndi\\ndare\\nil\\nproprio\\nnom e\\nal\\ngiorno\\nin\\ncui\\nsi\\ncelebra\\nl’am ore!\\nIn\\nrealtà\\nin\\nItalia,\\nnei\\nsecoli\\npiù\\nrecenti,\\nè\\nstato\\nricordato\\nsem plicem ente\\ncom e\\nuno\\ndei\\ntanti\\nm artiri\\ne\\nil\\nsuo\\ncollegam ento\\ncon\\nl’am ore\\nè\\nrim asto\\nquindi\\nsepolto\\nper\\nm olto\\ntem po.\\nForse\\nè\\nper\\nquesto\\nche\\ngli\\nitaliani\\nhanno\\nperso\\ne\\ndim enticato\\nquesta\\ntradizione\\nﬁnché\\nnon\\nl’hanno\\nrecuperata\\ngrazie\\nalla\\ncelebrità\\nche\\nha\\nnel\\nm ondo\\nanglofono.\\nO ggigiorno\\nin\\nItalia\\nogni\\nanno\\nsono\\ndavvero\\nnum erose\\nle\\niniziative\\ndedicate\\nalle\\ncoppie\\nnel\\nloro\\ngiorno\\nspeciale.', mimetype='text/plain', start_char_idx=0, end_char_idx=2014, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["nodes[18]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from docx import Document\n","from llama_index.core import Document as LLamaDocument\n","\n","# Function to load .docx content\n","def load_docx(file_path):\n","    doc = Document('data\\\\transcribed_data')\n","    text = []\n","    for paragraph in doc.paragraphs:\n","        text.append(paragraph.text)\n","    return \"\\n\".join(text)\n","\n","# Loading .docx file into LlamaIndex\n","def load_docx_into_llama(file_path):\n","    content = load_docx('data\\\\transcribed_data')\n","    llama_doc = LLamaDocument(content)\n","    return llama_doc\n","\n","# Example usage\n","docx_file = \"path_to_your_file.docx\"  # Replace with your actual file path\n","llama_doc = load_docx_into_llama(docx_file)\n","\n","# Assuming we have GPTSimpleVectorIndex available\n","from llama_index import GPTSimpleVectorIndex\n","index = GPTSimpleVectorIndex([llama_doc])\n","\n","# Example query\n","response = index.query(\"Your query here\")\n","print(response)\n"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":2}
